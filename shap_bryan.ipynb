{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is my attempt to do shap... I hope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_gbq\n",
    "import yfinance as yf\n",
    "import datetime\n",
    "\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets get some model output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = 'irlts-317602'\n",
    "# Full table path in gcp bigquery irlts-317602.2018.10eps_default_training\n",
    "dataset_name = '2017'\n",
    "table_name = '10eps_default'\n",
    "r_query = \"\"\"\n",
    "SELECT \n",
    "    data.* \n",
    "FROM \n",
    "    `irlts-317602.2018.10eps_default_training` as data \n",
    "WHERE \n",
    "    data.Episode = '8'\n",
    "\"\"\"\n",
    "query_result = pandas_gbq.read_gbq(r_query,project_id=project_id, progress_bar_type=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result.Date = query_result.Date.astype(np.datetime64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = query_result.set_index('Date').sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets get some feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "last_output_date = output_data.index.max()\n",
    "first_output_date = output_data.index.min()\n",
    "feature_df = yf.download('VOO',start=first_output_date,end=last_output_date, interval='1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df_subset = feature_df[['Adj Close','Volume']]\n",
    "# feature_df_subset.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets join these two dfs (hoping this goes well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = query_result.join(feature_df_subset,on=\"Date\",how = 'inner') #join the two datasets\n",
    "final_data.rename(columns={f'{j}':f'{j.lower()}'for i,j in enumerate(final_data.columns)},inplace = True) #fix columns because this is bothering me\n",
    "final_data.rename(columns={'adj close':'adj_close'},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'hold', 'buy', 'sell', 'choice', 'episode', 'adj_close',\n",
       "       'volume'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = final_data.choice\n",
    "x_train = final_data[['adj_close','volume']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction =prediction.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An attempt to do SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = len(x_train.columns)\n",
    "x = x_train.values[-1]\n",
    "reference = np.zeros(M) #adj_close,volume\n",
    "phi = kernel_shap(f, x, reference, M)\n",
    "base_value = phi[-1]\n",
    "shap_values = phi[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  reference = [0. 0.]\n",
      "          x = [2.3440921e+02 9.0370000e+06]\n",
      "shap_values = [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      " base_value = [0. 0. 0. 0.]\n",
      "   sum(phi) = 0.0\n",
      "       model output = 2\n"
     ]
    }
   ],
   "source": [
    "import scipy.special\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def powerset(iterable):\n",
    "    s = list(iterable)\n",
    "    return itertools.chain.from_iterable(itertools.combinations(s, r) for r in range(len(s)+1))\n",
    "\n",
    "def shapley_kernel(M,s):\n",
    "    if s == 0 or s == M:\n",
    "        return 10000\n",
    "    return (M-1)/(scipy.special.binom(M,s)*s*(M-s))\n",
    "\n",
    "def f(X):\n",
    "    \"\"\"\n",
    "    just pull the y value corresponding to x inputs\n",
    "    \"\"\"\n",
    "    # np.random.seed(0)\n",
    "    # beta = np.random.rand(X.shape[-1])\n",
    "    # return np.dot(X,beta) + 10\n",
    "    return prediction.values[-1]\n",
    "\n",
    "def kernel_shap(f, x, reference, M):\n",
    "    \"\"\"\n",
    "    Wrapper for the above functions\n",
    "    \"\"\"\n",
    "    X = np.zeros((2**M,M+1))\n",
    "    X[:,-1] = 1\n",
    "    weights = np.zeros(2**M) # initialize weights\n",
    "    V = np.zeros((2**M,M))\n",
    "    for i in range(2**M):\n",
    "        V[i,:] = reference\n",
    "\n",
    "    ws = {}\n",
    "    for i,s in enumerate(powerset(range(M))):\n",
    "        s = list(s)\n",
    "        V[i,s] = x[s]\n",
    "        X[i,s] = 1\n",
    "        ws[len(s)] = ws.get(len(s), 0) + shapley_kernel(M,len(s))\n",
    "        weights[i] = shapley_kernel(M,len(s))\n",
    "    y = f(V)\n",
    "    tmp = np.linalg.inv(np.dot(np.dot(X.T, np.diag(weights)), X))\n",
    "    return np.dot(tmp, np.dot(np.dot(X.T, np.diag(weights)), y))\n",
    "\n",
    "print(\"  reference =\", reference)\n",
    "print(\"          x =\", x)\n",
    "print(\"shap_values =\", shap_values)\n",
    "print(\" base_value =\", base_value)\n",
    "print(\"   sum(phi) =\", np.sum(phi))\n",
    "print(\"       model output =\", f(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "0 []\n",
      "[]\n",
      "1 [0]\n",
      "[[2.43352722e+02 2.85730000e+06]]\n",
      "2 [1]\n",
      "[[2.41671005e+02 5.14500000e+06]]\n",
      "3 [0, 1]\n",
      "[[2.43352722e+02 2.85730000e+06]\n",
      " [2.41671005e+02 5.14500000e+06]]\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((2**M,M+1))\n",
    "# print(X)\n",
    "X[:,-1] = 1\n",
    "# print(X)\n",
    "weights = np.zeros(2**M)\n",
    "V = np.zeros((2**M,M))\n",
    "for i in range(2**M):\n",
    "    V[i,:] = reference\n",
    "print(V)\n",
    "ws = {}\n",
    "for i,s in enumerate(powerset(range(M))):\n",
    "    s = list(s)\n",
    "    print(i,s)\n",
    "    print(x[s])\n",
    "    # V[i,s] = x[s].flatten()\n",
    "    # X[i,s] = 1\n",
    "    # ws[len(s)] = ws.get(len(s), 0) + shapley_kernel(M,len(s))\n",
    "    # weights[i] = shapley_kernel(M,len(s))\n",
    "# y = f(V)\n",
    "# tmp = np.linalg.inv(np.dot(np.dot(X.T, np.diag(weights)), X))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "231f708fbec9c535d090798f7039dd92c4e83641f529e9bb8d5e17a6b6157fe8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
